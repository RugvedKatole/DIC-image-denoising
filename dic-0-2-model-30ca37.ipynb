{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Denoising DIC data using Unet\n\n## **INDEX**\n\n1. DIC Image DATA generator\n2. Data Visualization\n3. Resnet50 Architecture\n4. U-net Architecture\n5. Prediction \n6. Result plots","metadata":{"id":"JIB-iBxuzggP"}},{"cell_type":"markdown","source":"# Import libraries","metadata":{"id":"Vj3ZO8Hb2k13"}},{"cell_type":"code","source":"import tensorflow.keras as keras\nimport os\nimport copy\nimport json\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom scipy.interpolate import interp2d\nimport numpy as np\nimport numpy.random as random\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D \nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom tensorflow.keras.layers import concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Add, Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam","metadata":{"id":"6TNr9ttx2hpX","execution":{"iopub.status.busy":"2021-09-29T08:19:49.641978Z","iopub.execute_input":"2021-09-29T08:19:49.642318Z","iopub.status.idle":"2021-09-29T08:19:54.148757Z","shell.execute_reply.started":"2021-09-29T08:19:49.642237Z","shell.execute_reply":"2021-09-29T08:19:54.147862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Generator","metadata":{"id":"9SQJFJbv2pmU"}},{"cell_type":"code","source":"\ndef dispgen(batch_size=32):\n  SubsetSize = 256\n  count = 1\n  total=1000\n  batch = np.zeros((n_batch,SubsetSize,SubsetSize))\n  while True:\n    for i in range(total):\n      for l in range(batch_size):\n            if (l <6):\n                s = 128\n            elif  (l<11):\n                s = 64\n            elif  (l<16):\n                s = 32\n            elif  (l<21):\n                s = 16\n            elif  (l<26):\n                s = 8\n            else:\n                s = 4\n            xp0=np.arange(1,SubsetSize/s+1,1/s)+2\n            yp0=np.arange(1,SubsetSize/s+1,1/s)+2\n            xxp0=np.arange(1,(SubsetSize/s)+4,1)\n            yyp0=np.arange(1,(SubsetSize/s)+4,1)        \n            u=random.randint(-100, 100, [int(SubsetSize/s+3),int(SubsetSize/s+3)])/115\n            disp_u = interp2d(xxp0,yyp0,u,kind='cubic')\n            disp_u_=disp_u(xp0,yp0)\n            batch[count-1] = disp_u_\n            count += 1\n            if count == batch_size:\n              retX = tf.convert_to_tensor(batch)\n              batch = np.zeros((n_batch,SubsetSize,SubsetSize))\n              count = 1\n              Noise= retX+np.random.normal(0,0.2,batch.shape)\n              yield Noise,retX\nn_batch = 32\n# call funtion to return generator object for displacement matrix\n#def getImage(gen):\n#  j = random.randint(0,n_batch-1)\n#  batch = next(gen)\n#  batch=tf.convert_to_tensor(batch)\n#  return batch[0],batch[0]+np.random.normal(0,0.2,batch[0].shape)\nUgen = dispgen(n_batch)","metadata":{"id":"x66KH8SY6oje","execution":{"iopub.status.busy":"2021-09-29T08:19:54.150322Z","iopub.execute_input":"2021-09-29T08:19:54.150585Z","iopub.status.idle":"2021-09-29T08:19:54.163203Z","shell.execute_reply.started":"2021-09-29T08:19:54.150548Z","shell.execute_reply":"2021-09-29T08:19:54.160766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization\nData Visualization is very important. When you know how your data looks then and then only you can process it in the way you want.","metadata":{"id":"6MzmvqVVlzl7"}},{"cell_type":"code","source":"x,y=next(Ugen)                    #X are the noisy images wit Mean 0 and SD 0.2 and Y are the original images.\nfor index in range(0,4):          #ploting Noising Data \n  plt.subplot(220 + 1 + index)\n  plt.imshow(x[index+10])\nplt.show()\n\nfor index in range(0,4):        # ploting Orignal Images\n  plt.subplot(220 + 1 + index)\n  plt.imshow(y[index+10])\n\nplt.show()","metadata":{"id":"fxRgXPlJAgvh","outputId":"d124215f-0199-43a4-a715-cc71c515e1ae","execution":{"iopub.status.busy":"2021-09-29T08:20:04.463839Z","iopub.execute_input":"2021-09-29T08:20:04.464381Z","iopub.status.idle":"2021-09-29T08:20:07.406172Z","shell.execute_reply.started":"2021-09-29T08:20:04.464345Z","shell.execute_reply":"2021-09-29T08:20:07.405507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building A Resnet50 Architecture","metadata":{"id":"gKLy3_qomxjZ"}},{"cell_type":"code","source":"def resBlock(input_tensor, num_channels=1):\n  conv1 = Conv2D(num_channels,(3,3),padding='same')(input_tensor)\n  relu  = Activation('relu')(conv1)\n  conv2 = Conv2D(num_channels,(3,3),padding='same')(relu)\n  add   = Add()([input_tensor, conv2])\n\n  output_tensor = Activation('relu')(add)\n  return output_tensor\n\ndef build_resnet_model(height,width,num_channels,num_res_blocks):\n    inp       = Input(shape=(height,width,1))\n    conv      = Conv2D (num_channels,(3,3),padding='same')(inp)\n    block_out = Activation('relu')(conv)\n\n    for i in np.arange(0,num_res_blocks):\n        block_out = resBlock(block_out, num_channels)\n\n    conv_m2   = Conv2D (1,(3,3),padding='same')(block_out)\n    add_m2    = Add()([inp, conv_m2])\n    model     = Model(inputs =inp,outputs = add_m2)\n\n    return model\n\nmodel = build_resnet_model(256,256,32,5)\nmodel.summary()","metadata":{"id":"lkoR7os6rrPF","outputId":"d96d5f86-dd9c-4e1f-b22a-ca452c12ae8b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# U-net Architecture\n","metadata":{"id":"c4O_J3-HJRXn"}},{"cell_type":"code","source":"def conv_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n    \"\"\"\n    Convolutional downsampling block\n    \n    Arguments:\n        inputs -- Input tensor\n        n_filters -- Number of filters for the convolutional layers\n        dropout_prob -- Dropout probability\n        max_pooling -- Use MaxPooling2D to reduce the spatial dimensions of the output volume\n    Returns: \n        next_layer, skip_connection --  Next layer and skip connection outputs\n    \"\"\"\n\n    conv = Conv2D(n_filters, # Number of filters\n                  3,   # Kernel size   \n                  activation='relu',\n                  padding='same',\n                  kernel_initializer='he_normal')(inputs)\n    conv = Conv2D(n_filters, # Number of filters\n                  3,   # Kernel size   \n                  activation='relu',\n                  padding='same',\n                  kernel_initializer='he_normal')(conv)\n    \n    # if dropout_prob > 0 add a dropout layer, with the variable dropout_prob as parameter\n    if dropout_prob > 0:\n        conv = Dropout(dropout_prob)(conv)\n    # if max_pooling is True add a MaxPooling2D with 2x2 pool_size\n    if max_pooling:\n        next_layer = MaxPooling2D(pool_size=(2,2))(conv)\n    else:\n        next_layer = conv\n        \n    skip_connection = conv\n    \n    return next_layer, skip_connection","metadata":{"id":"k2Z2QcUvXlW6","execution":{"iopub.status.busy":"2021-09-29T08:20:12.347096Z","iopub.execute_input":"2021-09-29T08:20:12.34782Z","iopub.status.idle":"2021-09-29T08:20:12.355174Z","shell.execute_reply.started":"2021-09-29T08:20:12.347785Z","shell.execute_reply":"2021-09-29T08:20:12.354193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def upsampling_block(expansive_input, contractive_input, n_filters=32):\n    \"\"\"\n    Convolutional upsampling block\n    \n    Arguments:\n        expansive_input -- Input tensor from previous layer\n        contractive_input -- Input tensor from previous skip layer\n        n_filters -- Number of filters for the convolutional layers\n    Returns: \n        conv -- Tensor output\n    \"\"\"\n    up = Conv2DTranspose(\n                n_filters,    # number of filters\n                 (3,3),    # Kernel size\n                 strides=(2,2),\n                 padding='same')(expansive_input)\n    \n    # Merge the previous output and the contractive_input\n    merge = concatenate([up, contractive_input], axis=3)\n    conv = Conv2D(n_filters, # Number of filters\n                  3,   # Kernel size   \n                  activation='relu',\n                  padding='same',\n                  kernel_initializer='he_normal')(merge)\n    conv = Conv2D(n_filters, # Number of filters\n                  3,   # Kernel size   \n                  activation='relu',\n                  padding='same',\n                  kernel_initializer='he_normal')(conv)\n    return conv","metadata":{"id":"P7NuxQM0L-O3","execution":{"iopub.status.busy":"2021-09-29T08:20:14.120933Z","iopub.execute_input":"2021-09-29T08:20:14.121199Z","iopub.status.idle":"2021-09-29T08:20:14.128151Z","shell.execute_reply.started":"2021-09-29T08:20:14.121171Z","shell.execute_reply":"2021-09-29T08:20:14.127162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unet_model(input_size=(256,256,1), n_filters=32, n_classes=1):\n    \"\"\"\n    Unet model\n    \n    Arguments:\n        input_size -- Input shape \n        n_filters -- Number of filters for the convolutional layers\n        n_classes -- Number of output classes\n    Returns: \n        model -- tf.keras.Model\n    \"\"\"\n    inputs = Input(input_size)\n    # Contracting Path (encoding)\n    # Add a conv_block with the inputs of the unet_ model and n_filters\n    cblock1 = conv_block(inputs,n_filters)\n    # Chain the first element of the output of each block to be the input of the next conv_block. \n    # Double the number of filters at each new step\n    cblock2 = conv_block(cblock1[0],2*n_filters)\n    cblock3 = conv_block(cblock2[0], 4*n_filters)\n    cblock4 = conv_block(cblock3[0], 8*n_filters, 0.3) # Include a dropout of 0.3 for this layer\n    # Include a dropout of 0.3 for this layer, and avoid the max_pooling layer\n    cblock5 = conv_block(cblock4[0],16*n_filters, 0.3, max_pooling=False) \n    # Expanding Path (decoding)\n    # Add the first upsampling_block.\n    # Use the cblock5[0] as expansive_input and cblock4[1] as contractive_input and n_filters * 8\n    ublock6 = upsampling_block(cblock5[0], cblock4[1],  8*n_filters)\n    # Chain the output of the previous block as expansive_input and the corresponding contractive block output.\n    # Note that you must use the second element of the contractive block i.e before the maxpooling layer. \n    # At each step, use half the number of filters of the previous block \n    ublock7 = upsampling_block(ublock6, cblock3[1],4*n_filters)\n    ublock8 = upsampling_block(ublock7, cblock2[1],2*n_filters)\n    ublock9 = upsampling_block(ublock8, cblock1[1], n_filters)\n\n\n    conv9 = Conv2D(n_filters,\n                 3,\n                 activation='relu',\n                 padding='same',\n                 kernel_initializer='he_normal')(ublock9)\n\n    conv10 = Conv2D(n_classes, 1, padding='same')(conv9)\n    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n    return model","metadata":{"id":"4I5AFReKMsTo","execution":{"iopub.status.busy":"2021-09-29T08:20:15.002494Z","iopub.execute_input":"2021-09-29T08:20:15.00324Z","iopub.status.idle":"2021-09-29T08:20:15.013108Z","shell.execute_reply.started":"2021-09-29T08:20:15.003184Z","shell.execute_reply":"2021-09-29T08:20:15.012299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training\n","metadata":{"id":"XrE9XuoJ34v9"}},{"cell_type":"code","source":"model=unet_model((256,256,1))\nmodel.compile(optimizer= Adam(beta_2 = 0.9),loss='mean_squared_error',metrics=['mse'])\nmodel.summary()","metadata":{"id":"7RcCYq9j8gGo","outputId":"98f72fbe-e14e-4243-b5f7-b3c41d180bb5","execution":{"iopub.status.busy":"2021-09-29T08:20:17.059891Z","iopub.execute_input":"2021-09-29T08:20:17.060507Z","iopub.status.idle":"2021-09-29T08:20:17.330825Z","shell.execute_reply.started":"2021-09-29T08:20:17.060466Z","shell.execute_reply":"2021-09-29T08:20:17.330145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating a checkpoint for every epoch","metadata":{"id":"vASD34jO69e-"}},{"cell_type":"code","source":"checkpoint_path = \"./\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n# Create a callback that saves the model's weights\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_weights_only=True,\n                                                 verbose=1)","metadata":{"id":"8D2_dA786GGH","execution":{"iopub.status.busy":"2021-09-29T08:20:25.627434Z","iopub.execute_input":"2021-09-29T08:20:25.627956Z","iopub.status.idle":"2021-09-29T08:20:25.632405Z","shell.execute_reply.started":"2021-09-29T08:20:25.627923Z","shell.execute_reply":"2021-09-29T08:20:25.631571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device('/device:GPU:0'):\n  history=model.fit(Ugen,steps_per_epoch=1250,epochs=10)","metadata":{"id":"dxEEdpbpIhq4","outputId":"22e15973-158a-4bf0-db1c-217f97dd91ee","execution":{"iopub.status.busy":"2021-09-29T08:20:55.906721Z","iopub.execute_input":"2021-09-29T08:20:55.907431Z","iopub.status.idle":"2021-09-29T09:29:34.330447Z","shell.execute_reply.started":"2021-09-29T08:20:55.907384Z","shell.execute_reply":"2021-09-29T09:29:34.329677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filepath='./Pbmodel1'\nmodel.save(\n    filepath, overwrite=True, include_optimizer=True,\n    signatures=None, options=None, save_traces=True\n)","metadata":{"id":"E86hh5TimIa5","execution":{"iopub.status.busy":"2021-09-29T09:29:34.332849Z","iopub.execute_input":"2021-09-29T09:29:34.333289Z","iopub.status.idle":"2021-09-29T09:29:38.357813Z","shell.execute_reply.started":"2021-09-29T09:29:34.333249Z","shell.execute_reply":"2021-09-29T09:29:38.357057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{"id":"O-X-6lStPI0O"}},{"cell_type":"code","source":"x_test_noisy,x=next(Ugen)\nresponse = model.predict(x_test_noisy)\nresponse=np.squeeze(response,axis=-1)","metadata":{"id":"u_STDjXArFZv","execution":{"iopub.status.busy":"2021-09-29T09:29:38.360651Z","iopub.execute_input":"2021-09-29T09:29:38.360895Z","iopub.status.idle":"2021-09-29T09:29:39.068238Z","shell.execute_reply.started":"2021-09-29T09:29:38.360864Z","shell.execute_reply":"2021-09-29T09:29:39.067504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Show some of the denoised examples.\nImages from left to right are - Noisy image, original image, denoised image","metadata":{"id":"LV7M7mq73931"}},{"cell_type":"code","source":"for index in range(24,30):\n  plt.subplot(330 + 1)\n  plt.imshow(x_test_noisy[index])\n  plt.subplot(330 + 2)\n  plt.imshow(x[index])\n  plt.subplot(330 + 3)\n  plt.imshow(response[index])\n  plt.show()","metadata":{"id":"Bgl8qeDcrXRI","execution":{"iopub.status.busy":"2021-09-29T09:29:39.070042Z","iopub.execute_input":"2021-09-29T09:29:39.070326Z","iopub.status.idle":"2021-09-29T09:29:40.840879Z","shell.execute_reply.started":"2021-09-29T09:29:39.07029Z","shell.execute_reply":"2021-09-29T09:29:40.84023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Result plots","metadata":{"id":"4kj1Z7Td4NTd"}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nimg_path ='../input/dic-measurements/img2.jpg'\nimg = image.load_img(img_path, target_size=(256,256))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx=tf.image.rgb_to_grayscale(x)\nx1=model.predict(x)\nplt.imshow(x[0])\nplt.show()\nprint(\"Noisy Image Data\")\nplt.imshow(x1[0])\nplt.show()\nprint(\"Denosed Image Data\")","metadata":{"execution":{"iopub.status.busy":"2021-09-29T09:50:34.883705Z","iopub.execute_input":"2021-09-29T09:50:34.883995Z","iopub.status.idle":"2021-09-29T09:50:35.575698Z","shell.execute_reply.started":"2021-09-29T09:50:34.883967Z","shell.execute_reply":"2021-09-29T09:50:35.574965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nimg_path ='../input/dic-measurements/img1.jpg'\nimg = image.load_img(img_path, target_size=(256,256))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx=tf.image.rgb_to_grayscale(x)\nx1=model.predict(x)\nplt.imshow(x[0])\nplt.show()\nprint(\"Noisy Image Data\")\nplt.imshow(x1[0])\nplt.show()\nprint(\"Denosed Image Data\")","metadata":{"execution":{"iopub.status.busy":"2021-09-29T09:50:48.604012Z","iopub.execute_input":"2021-09-29T09:50:48.604296Z","iopub.status.idle":"2021-09-29T09:50:49.037919Z","shell.execute_reply.started":"2021-09-29T09:50:48.604267Z","shell.execute_reply":"2021-09-29T09:50:49.034969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avg_mse   = []\navg_mean  = []\navg_sd    = []\n\nfor index in range(0,3):\n  avg_mean.append(np.mean(x[index] - response[index]))\n  avg_mse.append(np.mean((x[index] - response[index])**2))\n  avg_sd.append(np.std(x[index] - response[index]))\n\nprint(\"Mean:\", np.sum(avg_mean)/11)\nprint(\"MSE:\", np.sum(avg_mse)/11)\nprint(\"SD:\", np.sum(avg_sd)/11)","metadata":{"id":"_wlFGcwNw3CV","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"model.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-09-29T09:36:15.168806Z","iopub.execute_input":"2021-09-29T09:36:15.169068Z","iopub.status.idle":"2021-09-29T09:36:15.401258Z","shell.execute_reply.started":"2021-09-29T09:36:15.169041Z","shell.execute_reply":"2021-09-29T09:36:15.400565Z"},"trusted":true},"execution_count":null,"outputs":[]}]}